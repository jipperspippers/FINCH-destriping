{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3f78925d",
      "metadata": {
        "id": "3f78925d"
      },
      "source": [
        "# Code for the Hyperspectral Image Denoising via Matrix Factorization and Deep Prior Regularization Paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a4596db0",
      "metadata": {
        "id": "a4596db0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Conv3D, Dense, BatchNormalization, Concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# set seed for reproducibility\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e6845ee",
      "metadata": {
        "id": "1e6845ee"
      },
      "source": [
        "Initializations of:\n",
        "- M and N = size of image\n",
        "- L = spectral bands of image\n",
        "- X = image\n",
        "- sigma = standard deviation\n",
        "- N = white gaussain noise\n",
        "- S = sparse noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5a01ada5",
      "metadata": {
        "id": "5a01ada5"
      },
      "outputs": [],
      "source": [
        "# please note that the values of M, N, L might be changed in the future\n",
        "M, N, L = 512, 512, 640\n",
        "\n",
        "# M*N hyperspectral image with L spectral bands\n",
        "X = tf.random.uniform(shape=([M,N,L]), minval=-1, maxval=1, \n",
        "                      dtype=tf.float32, seed=42, name='X')\n",
        "\n",
        "# white Gaussian noise N(0, sigma**2)\n",
        "# sigma = \n",
        "# N = \n",
        "\n",
        "# sparse noise\n",
        "# S = np.random.default_rng().laplace(, , 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108e8718",
      "metadata": {
        "id": "108e8718"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I'm using functional API, as subclassing API is giving errors...**"
      ],
      "metadata": {
        "id": "APeqp_9Jl6c0"
      },
      "id": "APeqp_9Jl6c0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input as specified in the paper\n",
        "M, N, L = 180, 180, 1   # these are the values mentioned in the paper\n",
        "input_shape = (400, M, N, L)\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "# Skip connection\n",
        "inputs_skip_connection = list(input_shape)\n",
        "inputs_skip_connection[-1] = 64\n",
        "# inputs_skip_connection = inputs_skip_connection[2:]\n",
        "inputs_skip_connection = Input(shape=inputs_skip_connection)\n",
        "\n",
        "# Model starts\n",
        "model_input = input_layer\n",
        "# Block 1\n",
        "x = Conv3D(filters=64, kernel_size=(3,3,1), activation='relu', padding='same', strides=1, \n",
        "                  dilation_rate=1, name='block1')(model_input)\n",
        "x = BatchNormalization()(x)\n",
        "# Block 2\n",
        "x = Conv3D(filters=64, kernel_size=(3,3,64), activation='relu', padding='same', strides=1, \n",
        "           dilation_rate=2, name='block2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# Block 3\n",
        "x = Conv3D(filters=64, kernel_size=(3,3,64), activation='relu', padding='same', strides=1,\n",
        "           dilation_rate=4, name='block3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# Block 4\n",
        "x = Conv3D(filters=64, kernel_size=(3,3,64), activation='relu', padding='same', strides=1,\n",
        "           dilation_rate=3, name='block4')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# Block 5\n",
        "x = Conv3D(filters=64, kernel_size=(3,3,64), activation='relu', padding='same', strides=1,\n",
        "           dilation_rate=4, name='block5')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# Block 6\n",
        "x = Conv3D(filters=64, kernel_size=(3,3,64), activation='relu', padding='same', strides=1,\n",
        "           dilation_rate=2, name='block6')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# Block 7\n",
        "x = Conv3D(filters=64, kernel_size=(3,3,64), activation='relu', padding='same', strides=1,\n",
        "           dilation_rate=1, name='block7')(x)\n",
        "x = Concatenate(axis=1)([x, inputs_skip_connection])\n",
        "output = BatchNormalization()(x)"
      ],
      "metadata": {
        "id": "Z-ujU5yhknvx"
      },
      "id": "Z-ujU5yhknvx",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel = Model(model_input, output)\n",
        "mymodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "d-EX4oyMvW7J",
        "outputId": "0110866e-7cf6-4781-b41e-5e66a7c0c7d9"
      },
      "id": "d-EX4oyMvW7J",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ae6a5de51ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmymodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m    147\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 233\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    997\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             raise ValueError(\n\u001b[0;32m--> 999\u001b[0;31m                 \u001b[0;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m                 \u001b[0;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 f'were accessed without issue: {layers_with_complete_input}')\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 400, 180, 180, 64), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\") at layer \"concatenate_2\". The following previous layers were accessed without issue: ['block1', 'batch_normalization_12', 'block2', 'batch_normalization_13', 'block3', 'batch_normalization_14', 'block4', 'batch_normalization_15', 'block5', 'batch_normalization_16', 'block6', 'batch_normalization_17', 'block7']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcZPLfX6wbcL"
      },
      "id": "QcZPLfX6wbcL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc00f672",
      "metadata": {
        "id": "cc00f672"
      },
      "outputs": [],
      "source": [
        "class HSI_Model(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.block1 = layers.Conv3D(filters=64, kernel_size=(3,3,1), padding='same', strides=1, \n",
        "                                    dilation_rate=1, name='block1')\n",
        "        self.block2 = layers.Conv3D(filters=64, kernel_size=(3,3,64), padding='same', strides=1,\n",
        "                                   dilation_rate=2, name='block2')\n",
        "        self.block3 = layers.Conv3D(filters=64, kernel_size=(3,3,64), padding='same', strides=1,\n",
        "                                   dilation_rate=4, name='block3')\n",
        "        self.block4 = layers.Conv3D(filters=64, kernel_size=(3,3,64), padding='same', strides=1,\n",
        "                                   dilation_rate=3, name='block4')\n",
        "        self.block5 = layers.Conv3D(filters=64, kernel_size=(3,3,64), padding='same', strides=1,\n",
        "                                   dilation_rate=4, name='block5')\n",
        "        self.block6 = layers.Conv3D(filters=64, kernel_size=(3,3,64), padding='same', strides=1,\n",
        "                                   dilation_rate=2, name='block6')\n",
        "        self.block7 = layers.Conv3D(filters=64, kernel_size=(3,3,64), padding='same', strides=1,\n",
        "                                   dilation_rate=1, name='block7')\n",
        "        self.relu = layers.ReLU()\n",
        "        self.bnorm = layers.BatchNormalization()\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # block 1 (I wrote this in an expanded manner and the rest of the blocks in just 1 line)\n",
        "        x = inputs\n",
        "        # I modified the input as it was getting <=0 due to downsampling from block3\n",
        "        # Also, I had to change the padding from valid to same as the input was getting downsampled\n",
        "        # The below code under the comment debugging is made to match the dimensions for concatentation\n",
        "        # DEBUGGING\n",
        "        inputs_skip_connection = list(inputs.shape)\n",
        "        inputs_skip_connection[-1] = 64\n",
        "        inputs_skip_connection = inputs_skip_connection[1:]\n",
        "        inputs_skip_connection = layers.Input(shape=inputs_skip_connection)\n",
        "        # DEBUGGING\n",
        "        x = self.block1(inputs)\n",
        "        x = self.relu(x)\n",
        "        x = self.bnorm(x)\n",
        "        # block 2\n",
        "        x = self.bnorm(self.relu(self.block2(x)))\n",
        "        # block 3\n",
        "        x = self.bnorm(self.relu(self.block3(x)))\n",
        "        # block 4\n",
        "        x = self.bnorm(self.relu(self.block4(x)))\n",
        "        # block 5\n",
        "        x = self.bnorm(self.relu(self.block5(x)))\n",
        "        # block 6\n",
        "        x = self.bnorm(self.relu(self.block6(x)))\n",
        "        # block 7\n",
        "        x = self.block7(x)\n",
        "        x = layers.Concatenate(axis=1)([x,inputs_skip_connection])  # implements skip connection\n",
        "        output = self.relu(x)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 3 errors I am facing:\n",
        "- Since the input dimension is getting <=0 due to the downsampling action from block3, so I had to change the padding from valid to same\n",
        "- To implement the skip connection, I have to use the concatenate layer. For that I need to match the input dimension with the dimension of the output of block7. So, I changed the dimension of the input for skip connection from 1 to 64.\n",
        "- Finally, having resolved all these, I am now facing the error:\n",
        "```python\n",
        "\"Could not build a TypeSpec for KerasTensor(type_spec=TensorSpec(shape=(None, 800, 180, 180, 64), dtype=tf.float32, name=None), name='re_lu_8/Relu:0', description=\"created by layer 're_lu_8'\") of unsupported type <class 'keras.engine.keras_tensor.KerasTensor'>.\"\n",
        "```"
      ],
      "metadata": {
        "id": "PgeTeVh_JN9Q"
      },
      "id": "PgeTeVh_JN9Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00bd1ae5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "00bd1ae5",
        "outputId": "e25590bd-7c9f-417d-daa5-7330439c8130"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d949e10da7f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHSI_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    891\u001b[0m         3, \"Failed to convert %r to tensor: %s\" % (type(value).__name__, e))\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m   raise TypeError(f\"Could not build a TypeSpec for {value} of \"\n\u001b[0m\u001b[1;32m    894\u001b[0m                   f\"unsupported type {type(value)}.\")\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for KerasTensor(type_spec=TensorSpec(shape=(None, 800, 180, 180, 64), dtype=tf.float32, name=None), name='re_lu_8/Relu:0', description=\"created by layer 're_lu_8'\") of unsupported type <class 'keras.engine.keras_tensor.KerasTensor'>."
          ]
        }
      ],
      "source": [
        "# inputs = tf.keras.Input(shape=(None, M, N, L))\n",
        "M, N, L = 180, 180, 1   # these are the values mentioned in the paper\n",
        "input_shape = (400, M, N, L)\n",
        "model_input = layers.Input(shape=input_shape)\n",
        "\n",
        "model1 = HSI_Model()\n",
        "model1(model_input)\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c96fa73",
      "metadata": {
        "id": "7c96fa73"
      },
      "source": [
        "# Model Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e86942",
      "metadata": {
        "id": "f3e86942"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3    # also try 3e-4 (aka karpathy's constant)\n",
        "b1 = 0.9\n",
        "b2 = 0.999\n",
        "epsilon = 1e-8\n",
        "weight_decay = 1e-4\n",
        "optimizer = tf.keras.optimizers.experimental.Adam(learning_rate=lr, weight_decay=weight_decay, \n",
        "                                                  beta_1=b1, beta_2=b2, epsilon=epsilon)\n",
        "epochs = 60\n",
        "minibatch_size = 256\n",
        "\n",
        "# we'll have to design a custom loss function as specified in the paper\n",
        "\n",
        "model1.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0edc828",
      "metadata": {
        "id": "d0edc828"
      },
      "outputs": [],
      "source": [
        "model1(model_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab6910d",
      "metadata": {
        "id": "aab6910d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}